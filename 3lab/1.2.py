from sklearn.preprocessing import scale
import numpy as np
import pandas as pd

from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold

# Загрузка данных
data = pd.read_csv('E:\\ML\\3lab\\wine.data', header=None)

# Затем данные разделяются на признаки (X) и метки классов (y).
# X - это все столбцы с 1 по последний (при помощи .iloc), а y - первый столбец

# Здесь : в первой части среза означает, что мы берем все строки данных (все объекты),
# а 1: во второй части среза означает, что мы берем все столбцы, начиная со второго столбца (индекс 1).
X = data.iloc[:, 1:]

y = data.iloc[:, 0]

# настраивается объект kf
# Мы хотим разделить данные на пять частей, чтобы оценить модель на пяти разных наборах данных.
# shuffle установлен в True, данные будут случайным образом перемешаны перед разделением.
# Это важно, потому что перемешивание данных устраняет возможное влияние порядка данных на оценку модели.
kf = KFold(n_splits=5, shuffle=True, random_state=42)

# Создаем список для хранения точностей
accuracies = []
# В данном коде выполняется аналогичная процедура оценки производительности модели k-Nearest Neighbors (kNN) на данных,
# но перед оценкой модель была масштабирована

# Масштабирование признаков - это процедура приведения значений признаков в диапазон,
# который облегчает анализ и обучение моделей машинного обучения.

# Выполняется масштабирование признаков в матрице X с помощью функции scale.
# Это означает, что каждый признак будет масштабирован так, чтобы его среднее значение стало равным 0, а стандартное отклонение равным 1.
X_scaled = scale(X)
# Создаем список для хранения точностей после масштабирования
accuracies_scaled = []

# Перебираем значения k от 1 до 50
for k in range(1, 51):
    # Создаем модель kNN с текущим значением k
    knn = KNeighborsClassifier(n_neighbors=k)

    # Вычисляем точность на кросс-валидации после масштабирования
    scores = cross_val_score(knn, X_scaled, y, cv=kf, scoring='accuracy')

    # Среднее значение точности на кросс-валидации
    accuracy = np.mean(scores)

    # Добавляем точность после масштабирования в список
    accuracies_scaled.append(accuracy)

# Находим оптимальное значение k после масштабирования
best_k_scaled = np.argmax(accuracies_scaled) + 1
best_accuracy_scaled = accuracies_scaled[best_k_scaled - 1]

print("Оптимальное значение k после масштабирования:", best_k_scaled)
print("Максимальная точность после масштабирования:", best_accuracy_scaled)

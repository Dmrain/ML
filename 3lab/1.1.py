import pandas as pd
import numpy as np

from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold

# Загрузка данных
data = pd.read_csv('E:\\ML\\3lab\\wine.data', header=None)

# Затем данные разделяются на признаки (X) и метки классов (y).
# X - это все столбцы с 1 по последний (при помощи .iloc), а y - первый столбец

# Здесь : в первой части среза означает, что мы берем все строки данных (все объекты),
# а 1: во второй части среза означает, что мы берем все столбцы, начиная со второго столбца (индекс 1).
X = data.iloc[:, 1:]

y = data.iloc[:, 0]

# настраивается объект kf
# Мы хотим разделить данные на пять частей, чтобы оценить модель на пяти разных наборах данных.
# shuffle установлен в True, данные будут случайным образом перемешаны перед разделением.
# Это важно, потому что перемешивание данных устраняет возможное влияние порядка данных на оценку модели.
kf = KFold(n_splits=5, shuffle=True, random_state=42)

# Создаем список для хранения точностей
accuracies = []

# Этот код выполняет оценку модели k-ближайших соседей (kNN) с различными значениями k и сохраняет результаты оценки в accuracies
for k in range(1, 51):
    # Создается экземпляр модели kNN с текущим значением k.
    # Каждая итерация цикла использует разное количество соседей, начиная с одного и увеличивая k на каждой итерации
    knn = KNeighborsClassifier(n_neighbors=k)

    # Функция cross_val_score используется для оценки производительности модели с использованием метода кросс-валидации.
    # Кросс-валидация позволяет оценить, насколько хорошо модель обобщает данные, предсказывая новые, ранее не виденные примеры.
    # knn - это модель, которую мы хотим оценить
    # X представляет собой матрицу признаков, на которой будет обучаться и тестируться модель
    # y представляет собой вектор целевых классов или меток, которые модель должна предсказывать
    scores = cross_val_score(knn, X, y, cv=kf, scoring='accuracy')

    # Среднее значение оценок точности из всех разбиений данных сохраняется в переменной accuracy.
    # Это представляет собой среднюю точность модели kNN при данном значении k.
    accuracy = np.mean(scores)

    # Среднее значение точности добавляется в список accuracies.
    # В конечном итоге, accuracies будет содержать средние точности для каждого значения k от 1 до 50.
    accuracies.append(accuracy)

# функция argmax, которая находит индекс элемента в массиве accuracies,
# который имеет максимальное значение. Этот индекс соответствует k, на котором достигается наилучшая точность.
best_k = np.argmax(accuracies) + 1
# переменная, в которой мы хотим сохранить значение наилучшей точности, которую достигла модель при оптимальном значении k
best_accuracy = accuracies[best_k - 1]

print("Оптимальное значение k:", best_k)
print("Максимальная точность:", best_accuracy)
